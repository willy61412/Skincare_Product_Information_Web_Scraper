{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2PFvnSEbWnhT",
        "outputId": "24cdf381-3de2-4ce2-bfba-0d32877a3947"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DataFrame has been created successfully.\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "# Get all product URLs from all products page\n",
        "def get_urls(page_start, page_end):\n",
        "    all_products_url_part = []\n",
        "\n",
        "    for page in range(page_start, page_end + 1):\n",
        "        page_url = f'https://revisionskincare.com/collections/all-products?page={page}'\n",
        "        dom = requests.get(page_url).text\n",
        "        soup = BeautifulSoup(dom, 'html.parser')\n",
        "\n",
        "        product_urls = soup.find_all('h3', class_=\"product-card-title typography-text typography-text--body\")\n",
        "        for product_url in product_urls:\n",
        "            a_tag = product_url.find('a')\n",
        "            if a_tag and 'href' in a_tag.attrs:\n",
        "                href_value = a_tag['href']\n",
        "                all_products_url_part.append(href_value)\n",
        "\n",
        "    return all_products_url_part\n",
        "\n",
        "# Get all product information from every product page\n",
        "# Create a list to store all product information\n",
        "def main(product_url):\n",
        "    product_info = {\n",
        "        'Company Name': 'Revision Skincare',\n",
        "        'Product Title': '',\n",
        "        'Price': '',\n",
        "        'Product Ingredients': '',\n",
        "        'Key Ingredients': '',\n",
        "        'Website URL': product_url,\n",
        "        'Product Treat':'',\n",
        "        'Skin Type':'',\n",
        "        'Reviews Count':'',\n",
        "        'Reviews Stars':'',\n",
        "        'Before Image':'',\n",
        "        'After Image':''\n",
        "    }\n",
        "\n",
        "    # Use the html.parser parser to convert the HTML text into a BeautifulSoup object soup\n",
        "    dom = requests.get(product_url).text\n",
        "    soup = BeautifulSoup(dom, 'html.parser')\n",
        "\n",
        "    # Get product title\n",
        "    title_tag = soup.find('head').find('title')\n",
        "    product_info['Product Title'] = title_tag.text.strip()\n",
        "\n",
        "    # Get product price\n",
        "    price_span = soup.find('span', class_='price-item--regular')\n",
        "    if price_span:\n",
        "        product_info['Price'] = price_span.text.strip()\n",
        "    else:\n",
        "        product_info['Price'] = 'Price information not found.'\n",
        "\n",
        "    # Get all ingredients\n",
        "    modal_dialog_div = soup.find('modal-dialog', id='product-ingredients-modal-template--15772401238211__pdp-main')\n",
        "    if modal_dialog_div:\n",
        "        product_modal_div = modal_dialog_div.find('div', class_='product-modal-info typography-text typography-text--body')\n",
        "        p_tags = product_modal_div.find_all('p')\n",
        "        if p_tags:\n",
        "            ingredients = []\n",
        "            for p_tag in p_tags:\n",
        "                text = p_tag.text.strip()\n",
        "                info_list = [item.strip() for item in text.split(',')]\n",
        "                ingredients.extend(info_list)\n",
        "            product_info['Product Ingredients'] = ', '.join(ingredients)\n",
        "        else:\n",
        "            product_info['Product Ingredients'] = 'Product ingredients not found.'\n",
        "    else:\n",
        "        product_info['Product Ingredients'] = 'Product modal dialog not found.'\n",
        "        \n",
        "    # Get Key Ingredients\n",
        "    title_tag = soup.find('head').find('title')\n",
        "    product_info['Product Title'] = title_tag.text.strip()\n",
        "\n",
        "    panel_div = soup.find('div', class_='product-panel', id='three-panel')\n",
        "    if panel_div:\n",
        "        strong_tags = panel_div.find_all('strong')\n",
        "        if strong_tags:\n",
        "            key_ingredients = ', '.join([strong_tag.text.strip() for strong_tag in strong_tags])\n",
        "            product_info['Key Ingredients'] = key_ingredients\n",
        "        else:\n",
        "            product_info['Key Ingredients'] = 'Key Ingredients not found'\n",
        "    else:\n",
        "        product_info['Key Ingredients'] = 'Key Ingredients not found'\n",
        "\n",
        "    # Get Product Treat\n",
        "    treat_list = []\n",
        "    treat_tag = soup.find('div', class_='product-panel typography-text typography-text--body', id='one-panel')\n",
        "    if treat_tag:\n",
        "        treat_tag_2 = treat_tag.find('ul')\n",
        "        if treat_tag_2:\n",
        "            for item in treat_tag_2.find_all('li'):\n",
        "                treat_list.append(item.text.strip())\n",
        "            product_info['Product Treat'] = ', '.join(treat_list)\n",
        "        else:\n",
        "            product_info['Product Treat'] = 'Product treat not found.'\n",
        "    else:\n",
        "        product_info['Product Treat'] = 'Product treat not found.'\n",
        "\n",
        "    # Get Skin Type\n",
        "    product_div = soup.find('div', class_='product-panel typography-text typography-text--body', id='one-panel')\n",
        "    if product_div:\n",
        "        all_info = product_div.get_text(strip=True)\n",
        "        product_info['Skin Type'] = all_info\n",
        "    else:\n",
        "        product_info['Skin Type'] = 'Skin type information not found.'\n",
        "\n",
        "    # Get Reviews Count\n",
        "    product_reviews_div_parent = soup.find('div', class_=\"okeReviews-reviewsSummary-ratingCount\")\n",
        "    if product_reviews_div_parent:\n",
        "        product_reviews_div = product_reviews_div_parent.find('span')\n",
        "        if product_reviews_div:\n",
        "            product_info['Reviews Count'] = product_reviews_div.text.strip()\n",
        "        else:\n",
        "            product_info['Reviews Count'] = \"Reviews count not found.\"\n",
        "    else:\n",
        "        product_info['Reviews Count'] = \"Reviews count not found.\"\n",
        "\n",
        "    # Get Reviews Stars\n",
        "    product_star_span = soup.find('span', class_=\"okeReviews-a11yText\")\n",
        "    if product_star_span:\n",
        "        product_info['Reviews Stars'] = product_star_span.text.strip()\n",
        "    else:\n",
        "        product_info['Reviews Stars'] = \"Reviews stars not found.\"\n",
        "\n",
        "    # Get Before Image\n",
        "    product_before_img = soup.find('img', class_=\"image-before slider-image\")\n",
        "    if product_before_img:\n",
        "        src_url = product_before_img['src']\n",
        "        product_info['Before Image'] = src_url\n",
        "    else:\n",
        "        product_info['Before Image'] = \"Before image not found.\"\n",
        "\n",
        "    # Get After Image\n",
        "    product_after_img = soup.find('img', class_=\"image-after slider-image\")\n",
        "    if product_after_img:\n",
        "        src_url_2 = product_after_img['src']\n",
        "        product_info['After Image'] = src_url_2\n",
        "    else:\n",
        "        product_info['After Image'] = \"After image not found.\"\n",
        "\n",
        "    return product_info\n",
        "\n",
        "# Get URL from all product page 1-5\n",
        "if __name__ == '__main__':\n",
        "    all_products_url_part = get_urls(1, 5)\n",
        "    all_products_url = ['https://revisionskincare.com' + url for url in all_products_url_part]\n",
        "\n",
        "    # Create a list to store all product information\n",
        "    RS_product = []\n",
        "\n",
        "    # Loop through each product URL and collect product information\n",
        "    for product_url in all_products_url:\n",
        "        product_info = main(product_url)\n",
        "        RS_product.append(product_info)\n",
        "\n",
        "    # Convert the list of dictionaries into a DataFrame\n",
        "    df = pd.DataFrame(RS_product)\n",
        "    print(\"DataFrame has been created successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "unvsRzywoRD2"
      },
      "outputs": [],
      "source": [
        "print(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X4_GlAWtzoSt",
        "outputId": "7f51f61d-87f6-4db2-85e8-34580c5ef920"
      },
      "outputs": [],
      "source": [
        "# Data Cleaing\n",
        "import numpy as np\n",
        "df['Product Title'] = df['Product Title'].str.split('|').str[0]\n",
        "df['Product Title'] = df['Product Title'].str.split('–').str[0]\n",
        "df['Price'] = df['Price'].str.strip().str.replace('USD', '')\n",
        "df['Product Ingredients'] = df['Product Ingredients'].str.replace(r'^.*Ingredients:', '', regex=True)\n",
        "df['Product Ingredients'] = df['Product Ingredients'].apply(lambda x: x.title())\n",
        "df['Product Ingredients'] = df['Product Ingredients'].str.replace(\", Active Ingredients:\", \"\").apply(lambda x: x.strip().title())\n",
        "df['Product Ingredients'] = df['Product Ingredients'].apply(lambda x: x[2:] if x.startswith(\", \") else x)\n",
        "df['Key Ingredients'] = df['Key Ingredients'].str.replace('.', '').str.replace('D·E·J', '').str.strip()\n",
        "df['Skin Type'] = df['Skin Type'].str.replace(r'^.*benefits\\?', '', regex=True).str.strip()\n",
        "df['Skin Type'] = df['Skin Type'].str.replace(r'^.*Benefits\\?', '', regex=True).str.strip()\n",
        "df['Reviews Count'] = np.where(df['Reviews Count'] != 'Reviews count not found.', df['Reviews Count'].str.split().str[0], df['Reviews Count'])\n",
        "df['Reviews Stars'] = np.where(df['Reviews Stars'] != 'Reviews stars not found.', df['Reviews Stars'].str.replace(\"Rated \", \"\").str.split(\" out\", expand=True)[0], df['Reviews Stars'])\n",
        "df = df.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "uwFh676VpdGs",
        "outputId": "3252657d-8927-4946-c73f-6fd6f10ef5b9"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_bfab3d85-045b-419f-855a-d7adb137870e\", \"RS_products.xlsx\", 30311)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from google.colab import files\n",
        "df.to_excel('RS_products.xlsx', index=False)\n",
        "files.download('RS_products.xlsx')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
